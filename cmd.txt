myenv\Scripts\activate
cd C:/Users/bessghaier/projet_python_dssd
python Heart_Failure_Prediction.py

Accuracy:

Proportion of correct predictions (both positive and negative).


Recall (Sensitivity, True Positive Rate):

Proportion of actual positives correctly predicted.


F1-Score:

Harmonic mean of precision and recall.

Support:

The number of actual instances in each class (how many examples belong to each class).




Macro Average:

The unweighted average of the metrics for all classes (treats all classes equally, regardless of size).
Macro Average tells you how well the model performs across all classes equally, even if some classes are small.

Weighted Average:

The average of the metrics for all classes, weighted by their support (gives more importance to larger classes).
Weighted Average tells you how well the model performs overall, taking into account the real-world importance (size) of each class.



The model performs well overall, with 88% accuracy.
Class 0 (negative class) has slightly better precision than recall, meaning fewer false alarms but some missed detections.
Class 1 (positive class) has slightly better recall than precision, meaning fewer missed positives but slightly more false alarms.
Both macro and weighted averages confirm that the model is balanced across the classes.